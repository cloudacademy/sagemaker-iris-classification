{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9705aa3f",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Jupyter notebooks are divided into cells that can contain markdown or code that you can run interactively from the notebook interface. You can progress through the cells in the notebook by clicking the play button in the notebook tab's toolbar:\n",
    "\n",
    "![](assets/2024-09-09-09-50-34.png)\n",
    "\n",
    "Click the play button to advance to the next cell and continue on in the lab whenever you have completed a cell.\n",
    "\n",
    "After clicking the play button, the status in the left-hand side of the bottom status bar will change from **Idle** to **Busy**:\n",
    "\n",
    "![](assets/2024-09-09-09-50-00.png)\n",
    "\n",
    "Wait for the status to change back to **Idle** before proceeding to the next cell.\n",
    "\n",
    "#### Notebook Overview\n",
    "\n",
    "This notebook walks through the process for preparing data and then training a model using Amazon SageMaker HyperParameter Tuning.\n",
    "\n",
    "The dataset you will be using is the [public domain Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is a popular dataset for demonstrating classification with machine learning. The dataset consists of 150 samples of iris flowers. Using the numeric features of the flowers, such as sepal length and width, you will train a model that can classify each flower into one of three of the Iris flower species: setosa, versicolor, or virginica.\n",
    "\n",
    "You will use Python 3 as the programming language. This notebook is built on the SageMaker notebook conda_python3 environment. conda refers to Anaconda which is a data science platform. The environment comes with many common Python machine learning and data science libraries already installed.\n",
    "\n",
    "### Installing Dependencies\n",
    "\n",
    "To begin, you will ensure that you have the versions of the dependencies required by this lab. Run the following cell to install the versions of the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f537ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip install boto3==1.35.4 sagemaker==2.229.0 scikit-learn==1.5.1 numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea451035",
   "metadata": {},
   "source": [
    "*Note*: You may see some warnings when running the cell above. These warnings are expected and can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a28bd",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries\n",
    "\n",
    "You are using the popular `numpy` and `pandas` libraries for data manipulation, along with `boto3` and `sagemaker` for interacting with Amazon SageMaker and Amazon S3 resources. Run the following cell to import them and create a SageMaker client session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81245351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import numpy as np                                      \n",
    "import pandas as pd                                     \n",
    "from sklearn.model_selection import train_test_split   \n",
    "\n",
    "import os\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e365d37",
   "metadata": {},
   "source": [
    "### Getting the Notebook's IAM Role\n",
    "\n",
    "To interact with SageMaker, you need an IAM role that grants the necessary permissions. A role was created for you during lab setup that grants access to Amazon S3 and to create and run Amazon SageMaker HyperParameter Tuning jobs.\n",
    "\n",
    "Run the following cell to get the role associated with the notebook instance and store it in a variable for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5fd80",
   "metadata": {},
   "source": [
    "### Configuring Storage\n",
    "\n",
    "To train a model, you need to access a dataset, to prepare the data for training, and then store the model artifacts. Using Amazon S3 for storage is a best practice when working with Amazon SageMaker.\n",
    "\n",
    "The following cell retrieves the name of a bucket beginning with `lab-notebook-` that was created for you during lab setup.\n",
    "\n",
    "Run the following cell to configure storage for your HyperParameter training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f017256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"iris\"\n",
    "bucket = next((bucket['Name'] for bucket in boto3.client('s3').list_buckets()['Buckets'] if bucket['Name'].startswith('lab-notebook-')), None)\n",
    "\n",
    "session = sagemaker.Session(default_bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce10904",
   "metadata": {},
   "source": [
    "### Loading and Displaying the Data\n",
    "\n",
    "To load the `iris.csv` dataset, you will use the `pandas` library. The dataset contains four features: sepal length, sepal width, petal length, and petal width. The target column is the species of the iris flower.\n",
    "\n",
    "Run the following cell to load the dataset into a Pandas data frame and display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62bdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('./iris.csv', sep=',')\n",
    "pd.set_option('display.max_columns', 11)     \n",
    "pd.set_option('display.max_rows', 5)     \n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f657b0",
   "metadata": {},
   "source": [
    "### Preparing the Data for Training\n",
    "\n",
    "Typically, when training a machine learning model, you need to split the dataset into training and validation sets. The training set is used to train the model, and the validation set is used to evaluate the model's performance.\n",
    "\n",
    "As this dataset is small, no preprocessing is required apart from splitting the data. When working with larger and more complex datasets, you may need to perform additional preprocessing steps, such as normalizing the data or encoding categorical variables.\n",
    "\n",
    "It is conventional when performing classification tasks to reorder the data so that the target variable is the first column.\n",
    "\n",
    "The following cell splits the data into training, validation, and test datasets. The training dataset contains 70% of the data, the validation dataset contains 20%, and the test dataset contains 10%.\n",
    "\n",
    "Run the following cell to split the dataset into training and validation sets, re-order the columns, and display the first few rows of each dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebd73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, remaining_data = train_test_split(data, test_size=0.3, random_state=1729, stratify=data['Species'])\n",
    "validation_data, test_data = train_test_split(remaining_data, test_size=1/3, random_state=1729, stratify=remaining_data['Species'])\n",
    "\n",
    "train_data[['Species'] + [col for col in train_data.columns if col != 'Species']].to_csv('train.csv', index=False, header=False)\n",
    "validation_data[['Species'] + [col for col in validation_data.columns if col != 'Species']].to_csv('validation.csv', index=False, header=False)\n",
    "test_data[['Species'] + [col for col in test_data.columns if col != 'Species']].to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nValidation Data:\")\n",
    "print(validation_data.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5e5a8",
   "metadata": {},
   "source": [
    "### Uploading the Datasets to Amazon S3\n",
    "\n",
    "Now that you have split the data into training and validation datasets, you have to make them available to the SageMaker service.\n",
    "\n",
    "The following cell creates Amazon S3 prefixes and URIs for the training and validation datasets. The datasets will be stored in different prefixes within the same bucket. You will use the S3 URIs when configuring the SageMaker HyperParameter Tuning job.\n",
    "\n",
    "Run the following cell to upload the training and validation datasets to the Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "213d696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = sagemaker.image_uris.retrieve('xgboost', region, '1.0-1')\n",
    "\n",
    "train_s3_key = '{}/train'.format(prefix)\n",
    "validation_s3_key = '{}/validation'.format(prefix)\n",
    "\n",
    "s3_input_train = 's3://{}/{}'.format(bucket, train_s3_key)\n",
    "s3_input_validation ='s3://{}/{}'.format(bucket, validation_s3_key)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(train_s3_key, 'train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(validation_s3_key, 'validation.csv')).upload_file('validation.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b837e",
   "metadata": {},
   "source": [
    "### Configuring a HyperParameter Tuning Job\n",
    "\n",
    "The following cell creates a variable named `tuning_job_config` that contains the configuration for the SageMaker HyperParameter Tuning job.\n",
    "\n",
    "The `ParameterRanges` section specifies the parameters that are tunable. Each of these parameters can be changed to help prevent over fitting, and control the complexity of the model.\n",
    "\n",
    "When using Amazon HyperParameter Tuning with SageMaker, these parameters are modified iteratively to find the best combination of parameters for the model. Automating this tuning is often more efficient than manually tuning the parameters.\n",
    "\n",
    "The `ResourceLimits` section specifies the maximum number of training jobs that can be run in parallel and the maximum number of training jobs that can be run in total. In this lab, the numbers are small because the dataset is small, and the training jobs are quick to complete. In a non-lab environment, you may want to increase these numbers to speed up the tuning process.\n",
    "\n",
    "The `HyperParameterTuningJobObjective` section specifies the metric that you want to optimize. In this case, you are optimizing the validation loss. This is suitable for classification tasks where the goal is to minimize the loss. For other types of machine learning tasks, such as predicting a continuous value, you may want to optimize a different metric.\n",
    "\n",
    "Your tuning job configuration is using the `Bayesian` strategy. This strategy balances iteratively exploring new hyperparameter values based on the results of previous iterations, with exploiting the best values found so far.\n",
    "\n",
    "You are using `mlogloss` as the objective metric to optimize which is suitable for multi-class classification tasks. The goal is to minimize the log loss.\n",
    "\n",
    "Run the following cell to create a configuration for a HyperParameter Tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e426c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "        \"ContinuousParameterRanges\": [\n",
    "            {\n",
    "                \"Name\": \"eta\",\n",
    "                \"MinValue\": \"0.1\",\n",
    "                \"MaxValue\": \"0.5\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"min_child_weight\",\n",
    "                \"MinValue\": \"0\",\n",
    "                \"MaxValue\": \"120\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"subsample\",\n",
    "                \"MinValue\": \"0.5\",\n",
    "                \"MaxValue\": \"1\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"colsample_bytree\",\n",
    "                \"MinValue\": \"0.5\",\n",
    "                \"MaxValue\": \"1\"\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"gamma\",\n",
    "                \"MinValue\": \"0\",\n",
    "                \"MaxValue\": \"5\"\n",
    "            }\n",
    "        ],\n",
    "        \"IntegerParameterRanges\": [\n",
    "            {\n",
    "                \"Name\": \"max_depth\",\n",
    "                \"MinValue\": \"1\",\n",
    "                \"MaxValue\": \"10\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "        \"MaxNumberOfTrainingJobs\": 9,\n",
    "        \"MaxParallelTrainingJobs\": 3\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",  \n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "        \"MetricName\": \"validation:mlogloss\",\n",
    "        \"Type\": \"Minimize\"  \n",
    "    },\n",
    "    \"RandomSeed\": 123\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466f21c",
   "metadata": {},
   "source": [
    "### Defining a HyperParameter Training Job\n",
    "\n",
    "The following cell creates a variable named `training_job_config` that contains the configuration for the SageMaker HyperParameter Tuning training job.\n",
    "\n",
    "You are using a managed algorithm container image provided by Amazon SageMaker called XGBoost (eXtreme Gradient Boosting). This is a popular algorithm for classification tasks. Amazon SageMaker supports using your own docker container image if you have a custom algorithm or custom dependencies.\n",
    "\n",
    "Notice that as well as specifying the `TrainingImage`, you also are providing a `RoleArn`. The role is used by SageMaker to access the training data and to store the model artifacts in Amazon S3.\n",
    "\n",
    "The `StaticHyperParameters` section specifies the hyperparameters that are not tunable. These will remain constant throughout the tuning process.\n",
    "\n",
    "Run the following cell to define a HyperParameter Tuning training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = sagemaker.image_uris.retrieve('xgboost', region, '1.0-1')\n",
    "\n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"ContentType\": \"csv\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_input_train\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"ContentType\": \"csv\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_input_validation\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": \"s3://{}/{}output\".format(bucket, prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m5.large\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "        \"objective\": \"multi:softmax\",  \n",
    "        \"num_class\": \"3\", \n",
    "        \"eval_metric\": \"mlogloss\",  \n",
    "        \"num_round\": \"100\" \n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 300\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d092fa0",
   "metadata": {},
   "source": [
    "### Launching the HyperParameter Tuning Job\n",
    "\n",
    "To launch the HyperParameter Tuning job, you use the SageMaker Boto3 client to call the `create_hyper_parameter_tuning_job` method. The Amazon SageMaker service expects to be called with a tuning job configuration and training job definition, as well as a name for the job.\n",
    "\n",
    "Run the following cell to launch the HyperParameter Tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae94d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = \"iris-training-job\"\n",
    "\n",
    "smclient.create_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name,\n",
    "    HyperParameterTuningJobConfig=tuning_job_config,\n",
    "    TrainingJobDefinition=training_job_definition,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097550f1",
   "metadata": {},
   "source": [
    "Return to the lab and proceed to the next step to observe the progress of the HyperParameter Tuning job."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
